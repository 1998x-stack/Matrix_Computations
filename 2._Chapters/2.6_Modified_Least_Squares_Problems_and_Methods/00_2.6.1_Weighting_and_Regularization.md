# 00_2.6.1_Weighting_and_Regularization

"""

Lecture: 2._Chapters/2.6_Modified_Least_Squares_Problems_and_Methods
Content: 00_2.6.1_Weighting_and_Regularization

"""

### 详细分析权重与正则化

在《Matrix Computations》一书的第6章，第6.1节对权重和正则化进行了详细讨论。以下是对第2.6.1节“权重与正则化”的详细分析：

#### 1. 引言与背景

在最小二乘问题中，权重与正则化是两个重要的修改方式。权重方法主要处理每个方程在最小化 $\|Ax - b\|_2^2$ 中的重要性，而正则化方法则是在矩阵 $A$ 病态时，控制解向量 $x$ 的大小。

#### 2. 行权重

在普通最小二乘问题中，目标是最小化 $\|Ax - b\|_2^2$，即：
$$ \|Ax - b\|_2^2 = \sum_{i=1}^m (a_i^T x - b_i)^2 $$
其中 $A \in \mathbb{R}^{m \times n}$，$b \in \mathbb{R}^m$，$a_i$ 是矩阵 $A$ 的第 $i$ 行。在加权最小二乘问题中，我们引入一个对角权重矩阵 $D = \text{diag}(d_1, \ldots, d_m)$，并最小化：
$$ \|D(Ax - b)\|_2^2 = \sum_{i=1}^m d_i^2 (a_i^T x - b_i)^2 $$
这种方式可以改变每个方程在最小化中的权重。通过引入权重矩阵 $D$，我们可以将问题转化为带有加权矩阵的新问题。

#### 3. 列权重

列权重的方法是通过调整矩阵 $A$ 的列来反映其不确定性。假设 $G \in \mathbb{R}^{n \times n}$ 是非奇异的，定义 $G$-范数为：
$$ \|x\|_G = \|G^{-1} x\|_2 $$
我们最小化 $\|(AG^{-1})y - b\|_2$，得到的解为 $\hat{x} = G^{-1} \hat{y}$。这种方法在处理不同列尺度的矩阵时非常有效。

#### 4. 正则化

正则化是处理病态问题的一种重要方法。岭回归（Ridge Regression）和Tikhonov正则化是两种常见的正则化方法：

**岭回归**：
岭回归的目标是最小化以下目标函数：
$$ \|Ax - b\|_2^2 + \lambda \|x\|_2^2 $$
通过引入正则化参数 $\lambda$，控制解的范数。正常方程为：
$$ (A^T A + \lambda I)x = A^T b $$
通过SVD，可以将问题转换为对角形式，并通过选择适当的 $\lambda$ 来获得稳定的解。

**Tikhonov正则化**：
Tikhonov正则化的目标是最小化以下目标函数：
$$ \|Ax - b\|_2^2 + \lambda \|Bx\|_2^2 $$
其中 $B$ 是正则化矩阵。正常方程为：
$$ (A^T A + \lambda B^T B)x = A^T b $$
通过广义奇异值分解（GSVD），可以同时对角化 $A$ 和 $B$，从而简化问题。

#### 5. 算法实现与分析

**算法6.1.1**：利用行权重解决加权最小二乘问题
1. 构建加权矩阵 $D$ 并计算加权后的矩阵 $A$ 和向量 $b$。
2. 使用QR分解或SVD求解加权最小二乘问题。

**算法6.1.2**：利用列权重解决加权最小二乘问题
1. 构建列权重矩阵 $G$ 并计算加权后的矩阵 $AG^{-1}$。
2. 使用QR分解或SVD求解加权最小二乘问题，并将解转换回原始空间。

**算法6.1.3**：岭回归的正则化求解
1. 计算矩阵 $A$ 的SVD分解。
2. 通过选择适当的正则化参数 $\lambda$，计算稳定的最小二乘解。

**算法6.1.4**：Tikhonov正则化的求解
1. 计算矩阵 $A$ 和 $B$ 的GSVD分解。
2. 通过选择适当的正则化参数 $\lambda$，计算稳定的最小二乘解。

### 结论

权重与正则化方法在最小二乘问题中具有重要作用。通过合理选择权重和正则化参数，可以在保持计算稳定性的同时，提高解的准确性和可靠性。这些方法在处理病态矩阵和不确定性较大的数据时尤为有效。
